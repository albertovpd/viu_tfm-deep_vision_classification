{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating folders with synthetic data.\n",
    "\n",
    "In this notebook https://github.com/albertovpd/viu_tfm-deep_vision_classification/blob/kfolds_validation/src/creating_5_subfolders_for_kfoldslike_validation.ipynb were did the following:\n",
    "- For all available data, it was shuffled and taken 150 pics of each class for the test set.\n",
    "- The remaining pics were at first shuffled again, and then distributed in train/validation folders (80-20%).\n",
    "\n",
    "Now, 3 new folders will be created with 50, 250 and 480 synthetic pics for each class. So:\n",
    "- The same 150 pics are taken for the test set.\n",
    "- The same train/validation distribution (80-20%) is taken.\n",
    "- 50 synth pics of each class are randomly chosen, added to the real ones to create the folder *\"synth50_train_val_ds\"*. The same process is repeated with 250 and 480 synth pics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# local path\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import numpy as np\n",
    "import shutil\n",
    "import random\n",
    "import shutil\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# local\n",
    "load_dotenv()\n",
    "base_folder = os.environ.get(\"INPUT_PATH\")\n",
    "\n",
    "real_input  = base_folder + \"House_Room_Dataset-5_rooms/\"\n",
    "synth_input = base_folder + \"common_misclassifications/mosaics/\"\n",
    "synth_input_base = base_folder + \"common_misclassifications/\"\n",
    "synth_output= base_folder + \"dataset_synth_data-1test_3trainval_20220525/\"\n",
    "\n",
    "classes = {\n",
    "    'Dinning/' : 'dinning_fakes/', \n",
    "   'Bedroom/' : 'bedroom_fakes/',\n",
    "   'Livingroom/' : 'livingroom_fakes/',\n",
    "   'Kitchen/' : 'kitchen_fakes/',\n",
    "   'Bathroom/': 'bathroom_fakes/'\n",
    "            }\n",
    "\n",
    "new_folders = {\n",
    "    \"no_synth_train_val_ds/\": 0, # without fake pics\n",
    "    \"synth50_train_val_ds/\" : 50, \n",
    "    \"synth250_train_val_ds/\": 250, \n",
    "    \"synth480_train_val_ds/\": 480\n",
    "                }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- create folders for train, test, validation\n",
    "- merge the input pics and divide them into that folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in classes:\n",
    "    # create subfolders with fraction     \n",
    "    os.makedirs(synth_output + 'train_ds/' + c, exist_ok = True)\n",
    "    os.makedirs(synth_output + 'val_ds/' + c, exist_ok = True)   \n",
    "    os.makedirs(synth_output + 'test_ds/' + c, exist_ok = True) \n",
    "    \n",
    "    # getting pics\n",
    "    real_pics = os.listdir(real_input+c)\n",
    "        \n",
    "    # shuffle them and split into train/val (test pics already separated)\n",
    "    np.random.seed()\n",
    "    np.random.shuffle(real_pics)\n",
    "    \n",
    "    # get 150 pics of each class for test ds\n",
    "    test_ds, train_val_ds = np.split(np.array(real_pics),[150])\n",
    "    \n",
    "    # shuffle and split them again\n",
    "    np.random.seed()\n",
    "    np.random.shuffle(train_val_ds)    \n",
    "    # get 80% of the remaining for train ds, 20% of the remaining for val ds\n",
    "    train_ds, val_ds = np.split(np.array(train_val_ds),[int(0.8 * len(train_val_ds))])\n",
    "\n",
    "    # copying real pics to new folders        \n",
    "    for train_pic in train_ds:\n",
    "        shutil.copyfile(real_input + c + train_pic, synth_output + \"train_ds/\" + c + train_pic)\n",
    "    for val_pic in val_ds:\n",
    "        shutil.copyfile(real_input + c + val_pic, synth_output + \"val_ds/\"   + c + val_pic)\n",
    "    for test_pic in test_ds:\n",
    "        shutil.copyfile(real_input + c + test_pic, synth_output + \"test_ds/\"   + c + test_pic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------\n",
    "\n",
    "- now we got all real pics shuffled in the *test_ds, train_ds, val_ds* folder.\n",
    "- let's create the folders within the *new_folders* dictionary and copy train_ds and val_ds to all of them (*test_ds* will remain unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copying all real pics to the 3 new folders\n",
    "for n in new_folders:\n",
    "    for c in classes:\n",
    "        \n",
    "        # create the new folders\n",
    "        os.makedirs(synth_output + n + \"train_ds/\"+ c, exist_ok = True)\n",
    "        os.makedirs(synth_output + n + \"val_ds/\"+ c, exist_ok = True)\n",
    "        \n",
    "        train_set = os.listdir(synth_output + \"train_ds/\" + c )\n",
    "        val_set = os.listdir(synth_output + \"val_ds/\" + c )\n",
    "        \n",
    "        for t in train_set:\n",
    "            shutil.copyfile(synth_output + \"train_ds/\" + c + t, synth_output + n + \"train_ds/\" + c + t)\n",
    "        for v in val_set:\n",
    "            shutil.copyfile(synth_output + \"val_ds/\" + c + v,   synth_output + n + \"val_ds/\"   + c + v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- fake images have 256x256 resolution and they have to be changed into 224x224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 224, 224\n",
    "for c in classes:\n",
    "    # read path\n",
    "    pic_list = os.listdir(synth_input+classes[c])\n",
    "    rescaled_path = synth_input_base+\"rescaled_x224/\"+classes[c]\n",
    "    output224 = os.makedirs(rescaled_path, exist_ok = True)\n",
    "    #print(rescaled_path)\n",
    "    \n",
    "    for p in pic_list:\n",
    "        im = Image.open(synth_input+classes[c]+ p)\n",
    "        im_resized = im.resize(size, Image.ANTIALIAS)    \n",
    "        im_resized.save(rescaled_path+p[:-4]+\".png\", \"PNG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- now add different amout of fake data to that folders as shows the associated values in the dictionary above, for train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bathroom_fakes',\n",
       " 'livingroom_fakes',\n",
       " 'dinning_fakes',\n",
       " 'bedroom_fakes',\n",
       " 'kitchen_fakes']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_folders = os.listdir(synth_input_base+\"rescaled_x224/\")\n",
    "fake_folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no_synth_train_val_ds/ Dinning/ 0  fake pics added\n",
      "no_synth_train_val_ds/ Bedroom/ 0  fake pics added\n",
      "no_synth_train_val_ds/ Livingroom/ 0  fake pics added\n",
      "no_synth_train_val_ds/ Kitchen/ 0  fake pics added\n",
      "no_synth_train_val_ds/ Bathroom/ 0  fake pics added\n",
      "synth50_train_val_ds/ Dinning/ 50  fake pics added\n",
      "synth50_train_val_ds/ Bedroom/ 50  fake pics added\n",
      "synth50_train_val_ds/ Livingroom/ 50  fake pics added\n",
      "synth50_train_val_ds/ Kitchen/ 50  fake pics added\n",
      "synth50_train_val_ds/ Bathroom/ 50  fake pics added\n",
      "synth250_train_val_ds/ Dinning/ 250  fake pics added\n",
      "synth250_train_val_ds/ Bedroom/ 250  fake pics added\n",
      "synth250_train_val_ds/ Livingroom/ 250  fake pics added\n",
      "synth250_train_val_ds/ Kitchen/ 250  fake pics added\n",
      "synth250_train_val_ds/ Bathroom/ 250  fake pics added\n",
      "synth480_train_val_ds/ Dinning/ 480  fake pics added\n",
      "synth480_train_val_ds/ Bedroom/ 480  fake pics added\n",
      "synth480_train_val_ds/ Livingroom/ 480  fake pics added\n",
      "synth480_train_val_ds/ Kitchen/ 480  fake pics added\n",
      "synth480_train_val_ds/ Bathroom/ 480  fake pics added\n"
     ]
    }
   ],
   "source": [
    "# copying fake pics to the new folders\n",
    "for n in new_folders:\n",
    "    for c in classes:\n",
    "        \n",
    "        # locate fake pics and shuffle them\n",
    "        fake_pics = os.listdir(synth_input_base+\"rescaled_x224/\"+classes[c])\n",
    "        np.random.seed()\n",
    "        np.random.shuffle(fake_pics)\n",
    "        \n",
    "        # create a list of 50, 250 and 480 synthetic shuffled pics\n",
    "        fake_shuffled, _ = np.split(np.array(fake_pics),[new_folders[n]])\n",
    "        print(n, c, len(fake_shuffled), \" fake pics added\")\n",
    "        \n",
    "        # copy that pics into the new folders\n",
    "        for f in fake_shuffled:\n",
    "            shutil.copyfile(synth_input_base+\"rescaled_x224/\"+ classes[c] + f, synth_output + n + \"train_ds/\" + c + f)\n",
    "            #print(synth_output + n + c+f)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlsklearn",
   "language": "python",
   "name": "mlsklearn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
