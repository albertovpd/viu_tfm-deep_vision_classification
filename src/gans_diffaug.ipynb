{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"gans_diffaug.ipynb","provenance":[],"background_execution":"on","collapsed_sections":[],"authorship_tag":"ABX9TyOXgPcpxXlIq5qy5xyTGGv6"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["https://colab.research.google.com/gist/zsyzzsoft/5fbb71b9bf9a3217576bebae5de46fc2/data-efficient-gans.ipynb\n","\n","Thanks to:\n","- Zhao, Shengyu and Liu, Zhijian and Lin, Ji and Zhu, Jun-Yan and Han, Song\n","- Differentiable Augmentation for Data-Efficient GAN Training\n","- Conference on Neural Information Processing Systems (NeurIPS)\n","- 2020"],"metadata":{"id":"IXt0ZRb8Fpcg"}},{"cell_type":"code","source":["# Google Drive stuff\n","from google.colab import drive\n","drive.mount('/content/drive/', force_remount=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ALviHR0CH0bq","executionInfo":{"status":"ok","timestamp":1648913641113,"user_tz":-120,"elapsed":3703,"user":{"displayName":"Alberto Vargas","userId":"10932058389883875017"}},"outputId":"27d29e7c-f186-4d61-c79e-20764bee4ecb"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n"]}]},{"cell_type":"markdown","source":["- i broke pip"],"metadata":{"id":"iBvX50bz5BaP"}},{"cell_type":"code","source":["%ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UAI7IIDb5AM_","executionInfo":{"status":"ok","timestamp":1648913641681,"user_tz":-120,"elapsed":576,"user":{"displayName":"Alberto Vargas","userId":"10932058389883875017"}},"outputId":"cf47a25c-ad9f-41df-e462-39c2697769ca"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[0m\u001b[01;34mdrive\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"]}]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/2-Estudios/viu-master_ai/\n","%ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dvN53Blw5AW3","executionInfo":{"status":"ok","timestamp":1648913641683,"user_tz":-120,"elapsed":37,"user":{"displayName":"Alberto Vargas","userId":"10932058389883875017"}},"outputId":"93e50a68-1301-44eb-cb02-e520b180d7e8"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/2-Estudios/viu-master_ai\n"," \u001b[0m\u001b[01;36m07MAIR\u001b[0m@                                            \u001b[01;34mno_supervisado\u001b[0m/\n","\u001b[01;36m'07MAIR (1)'\u001b[0m@                                      \u001b[01;34m'Razonamiento aproximado'\u001b[0m/\n","'2a_matricula_master-Vargas Pina,Alberto_HM.xlsx'  \u001b[01;34m'redes neuronales'\u001b[0m/\n","\u001b[01;34m'algoritmos de optimización'\u001b[0m/                       \u001b[01;34mseminarios\u001b[0m/\n"," \u001b[01;34mdata-efficient-gans\u001b[0m/                               \u001b[01;34mtfm-deep_vision\u001b[0m/\n"," get-pip.py\n"]}]},{"cell_type":"code","source":["!python3 get-pip.py"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TyaIYZNS5AZV","executionInfo":{"status":"ok","timestamp":1648913649013,"user_tz":-120,"elapsed":7340,"user":{"displayName":"Alberto Vargas","userId":"10932058389883875017"}},"outputId":"a0342fbe-efd3-4534-b4f8-ef816ddc34eb"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pip\n","  Using cached pip-22.0.4-py3-none-any.whl (2.1 MB)\n","Installing collected packages: pip\n","  Attempting uninstall: pip\n","    Found existing installation: pip 22.0.4\n","    Uninstalling pip-22.0.4:\n","      Successfully uninstalled pip-22.0.4\n","Successfully installed pip-22.0.4\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]}]},{"cell_type":"code","source":["!pip uninstall tensorflow -y \n","!pip install tensorflow-gpu==1.15 & pip install tensorflow-datasets==2.1.0\n","# existing tensorflow: 2.8"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R_GgapP6ZMMU","executionInfo":{"status":"ok","timestamp":1648913772725,"user_tz":-120,"elapsed":18082,"user":{"displayName":"Alberto Vargas","userId":"10932058389883875017"}},"outputId":"1f79f61d-ee5c-42d6-9410-a8bb1d9e03ae"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["Found existing installation: tensorflow 1.15.2\n","Uninstalling tensorflow-1.15.2:\n","  Successfully uninstalled tensorflow-1.15.2\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0mRequirement already satisfied: tensorflow-gpu==1.15 in /usr/local/lib/python3.7/dist-packages (1.15.0)\n","Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /tensorflow-1.15.2/python3.7 (from tensorflow-gpu==1.15) (1.15.0)\n","Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15) (0.8.1)\n","Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15) (1.0.0)\n","Requirement already satisfied: keras-applications>=1.0.8 in /tensorflow-1.15.2/python3.7 (from tensorflow-gpu==1.15) (1.0.8)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15) (1.1.0)\n","Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15) (0.2.2)\n","Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15) (1.44.0)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15) (3.3.0)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15) (0.37.1)\n","Requirement already satisfied: tensorflow-estimator==1.15.1 in /tensorflow-1.15.2/python3.7 (from tensorflow-gpu==1.15) (1.15.1)\n","Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15) (1.14.0)\n","Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15) (1.21.5)\n","Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15) (1.1.2)\n","Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15) (3.17.3)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15) (1.15.0)\n","Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15) (0.2.0)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow-gpu==1.15) (3.1.0)\n","Collecting tensorflow-datasets==2.1.0\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15) (1.0.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15) (3.3.6)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15) (57.4.0)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15) (4.11.3)\n","Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.8->tensorflow-gpu==1.15) (1.5.2)\n","Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15) (3.10.0.2)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15) (3.7.0)\n","  Downloading tensorflow_datasets-2.1.0-py3-none-any.whl (3.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m39.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets==2.1.0) (1.15.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets==2.1.0) (4.63.0)\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets==2.1.0) (1.0.0)\n","Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets==2.1.0) (3.17.3)\n","Requirement already satisfied: wrapt in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets==2.1.0) (1.14.0)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets==2.1.0) (2.23.0)\n","Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets==2.1.0) (21.4.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets==2.1.0) (1.21.5)\n","Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets==2.1.0) (0.16.0)\n","Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets==2.1.0) (0.3.4)\n","Requirement already satisfied: termcolor in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets==2.1.0) (1.1.0)\n","Requirement already satisfied: promise in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets==2.1.0) (2.3)\n","Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets==2.1.0) (1.7.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->tensorflow-datasets==2.1.0) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->tensorflow-datasets==2.1.0) (2021.10.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->tensorflow-datasets==2.1.0) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->tensorflow-datasets==2.1.0) (2.10)\n","Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-metadata->tensorflow-datasets==2.1.0) (1.56.0)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0mInstalling collected packages: tensorflow-datasets\n","  Attempting uninstall: tensorflow-datasets\n","    Found existing installation: tensorflow-datasets 4.0.1\n","    Uninstalling tensorflow-datasets-4.0.1:\n","      Successfully uninstalled tensorflow-datasets-4.0.1\n","Successfully installed tensorflow-datasets-2.1.0\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]}]},{"cell_type":"code","source":["%tensorflow_version 1.x\n","import tensorflow as tf\n","print(tf.__version__)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BQrtwPrQ0qxD","executionInfo":{"status":"ok","timestamp":1648913778353,"user_tz":-120,"elapsed":8,"user":{"displayName":"Alberto Vargas","userId":"10932058389883875017"}},"outputId":"0628e9ee-6d9b-46ae-858e-a17c88e2a5e3"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["1.15.2\n"]}]},{"cell_type":"code","source":["# tf\n","#%tensorflow_version 2.x\n","#import tensorflow as tf\n","device_name = tf.test.gpu_device_name()\n","if device_name != '/device:GPU:0':\n","  raise SystemError('GPU device not found')\n","print('Found GPU at: {}'.format(device_name))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iGcCTz73VIrY","executionInfo":{"status":"ok","timestamp":1648913654727,"user_tz":-120,"elapsed":14,"user":{"displayName":"Alberto Vargas","userId":"10932058389883875017"}},"outputId":"91aebbe7-023b-4e09-ccfd-385a2109c916"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Found GPU at: /device:GPU:0\n"]}]},{"cell_type":"code","source":["# navigating through folder\n","import os"],"metadata":{"id":"sr82R4t0H0eb","executionInfo":{"status":"ok","timestamp":1648913654728,"user_tz":-120,"elapsed":10,"user":{"displayName":"Alberto Vargas","userId":"10932058389883875017"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["base_folder = \"/drive/My Drive/2-Estudios/viu-master_ai/tfm-deep_vision/\" #input/common_misclassifications/\"\n","src_folder =  base_folder+\"src/\"\n","output_folder = base_folder + \"/output/\""],"metadata":{"id":"UHNG8_ReH0hP","executionInfo":{"status":"ok","timestamp":1648913654729,"user_tz":-120,"elapsed":9,"user":{"displayName":"Alberto Vargas","userId":"10932058389883875017"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6Uc5NkzDFloM","executionInfo":{"status":"ok","timestamp":1648913655065,"user_tz":-120,"elapsed":344,"user":{"displayName":"Alberto Vargas","userId":"10932058389883875017"}},"outputId":"3078b2db-753e-430a-f911-cc0d168e104d"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[0m\u001b[01;34mBathroom\u001b[0m/  \u001b[01;34mBedroom\u001b[0m/  \u001b[01;34mDinning\u001b[0m/  \u001b[01;34mKitchen\u001b[0m/  \u001b[01;34mLivingroom\u001b[0m/\n"]}],"source":["%ls \"/content/drive/My Drive/2-Estudios/viu-master_ai/tfm-deep_vision/input/common_misclassifications/\""]},{"cell_type":"markdown","source":["- 1st test"],"metadata":{"id":"UjNwCVkNI8Le"}},{"cell_type":"code","source":["!git clone https://github.com/mit-han-lab/data-efficient-gans"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0MW5SKcoHDvw","executionInfo":{"status":"ok","timestamp":1648913655067,"user_tz":-120,"elapsed":13,"user":{"displayName":"Alberto Vargas","userId":"10932058389883875017"}},"outputId":"a07d3661-c4cd-4ed3-c2c2-88f19aef0b25"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["fatal: destination path 'data-efficient-gans' already exists and is not an empty directory.\n"]}]},{"cell_type":"code","source":["%ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WBERuNH0KHS6","executionInfo":{"status":"ok","timestamp":1648913655527,"user_tz":-120,"elapsed":466,"user":{"displayName":"Alberto Vargas","userId":"10932058389883875017"}},"outputId":"fac624e6-ec0b-4044-8840-ed04e5e1d4b7"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":[" \u001b[0m\u001b[01;36m07MAIR\u001b[0m@                                            \u001b[01;34mno_supervisado\u001b[0m/\n","\u001b[01;36m'07MAIR (1)'\u001b[0m@                                      \u001b[01;34m'Razonamiento aproximado'\u001b[0m/\n","'2a_matricula_master-Vargas Pina,Alberto_HM.xlsx'  \u001b[01;34m'redes neuronales'\u001b[0m/\n","\u001b[01;34m'algoritmos de optimización'\u001b[0m/                       \u001b[01;34mseminarios\u001b[0m/\n"," \u001b[01;34mdata-efficient-gans\u001b[0m/                               \u001b[01;34mtfm-deep_vision\u001b[0m/\n"," get-pip.py\n"]}]},{"cell_type":"code","source":["%cd data-efficient-gans/DiffAugment-stylegan2"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0WpUbbBRKHaw","executionInfo":{"status":"ok","timestamp":1648913655528,"user_tz":-120,"elapsed":21,"user":{"displayName":"Alberto Vargas","userId":"10932058389883875017"}},"outputId":"f80ad306-b9ea-49c9-9cf3-bbd3201b8d32"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/My Drive/2-Estudios/viu-master_ai/data-efficient-gans/DiffAugment-stylegan2\n"]}]},{"cell_type":"code","source":["%ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xdE0bX3qLvVn","executionInfo":{"status":"ok","timestamp":1648913655528,"user_tz":-120,"elapsed":15,"user":{"displayName":"Alberto Vargas","userId":"10932058389883875017"}},"outputId":"0a7930c1-bfc9-4bab-a1fb-987e24299737"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["DiffAugment_tf.py  generate_gif.py  \u001b[0m\u001b[01;34mmetrics\u001b[0m/   run_cifar.py  run_low_shot.py\n","\u001b[01;34mdnnlib\u001b[0m/            LICENSE.txt      README.md  run_ffhq.py   \u001b[01;34mtraining\u001b[0m/\n"]}]},{"cell_type":"code","source":["# my folder with pics\n","!ls \"/content/drive/My Drive/2-Estudios/viu-master_ai/tfm-deep_vision/input/common_misclassifications/Bathroom/\" "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aeBdJ011ODlk","executionInfo":{"status":"ok","timestamp":1648913655528,"user_tz":-120,"elapsed":10,"user":{"displayName":"Alberto Vargas","userId":"10932058389883875017"}},"outputId":"61617abc-e6c0-49ea-d93f-50e099433d7f"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["bath_1001.jpg  bath_1299.jpg  bath_323.jpg  bath_664.jpg  bath_876.jpg\n","bath_1016.jpg  bath_137.jpg   bath_334.jpg  bath_674.jpg  bath_884.jpg\n","bath_1026.jpg  bath_13.jpg    bath_384.jpg  bath_675.jpg  bath_896.jpg\n","bath_1055.jpg  bath_151.jpg   bath_38.jpg   bath_676.jpg  bath_900.jpg\n","bath_1075.jpg  bath_158.jpg   bath_41.jpg   bath_70.jpg   bath_932.jpg\n","bath_1082.jpg  bath_15.jpg    bath_425.jpg  bath_732.jpg  bath_934.jpg\n","bath_1148.jpg  bath_163.jpg   bath_447.jpg  bath_747.jpg  bath_936.jpg\n","bath_1149.jpg  bath_169.jpg   bath_450.jpg  bath_749.jpg  bath_938.jpg\n","bath_1183.jpg  bath_178.jpg   bath_466.jpg  bath_754.jpg  bath_955.jpg\n","bath_1194.jpg  bath_179.jpg   bath_529.jpg  bath_775.jpg  bath_958.jpg\n","bath_1196.jpg  bath_17.jpg    bath_536.jpg  bath_77.jpg   bath_975.jpg\n","bath_1235.jpg  bath_262.jpg   bath_547.jpg  bath_791.jpg  bath_991.jpg\n","bath_1239.jpg  bath_285.jpg   bath_552.jpg  bath_820.jpg  bath_998.jpg\n","bath_1247.jpg  bath_290.jpg   bath_557.jpg  bath_854.jpg\n","bath_1253.jpg  bath_291.jpg   bath_596.jpg  bath_859.jpg\n","bath_1262.jpg  bath_298.jpg   bath_620.jpg  bath_863.jpg\n","bath_1283.jpg  bath_321.jpg   bath_634.jpg  bath_872.jpg\n"]}]},{"cell_type":"code","source":["%ls \"/content/drive/My Drive/2-Estudios/viu-master_ai/tfm-deep_vision/input/common_misclassifications/Bathroom/\" | wc -l"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VqxmBTifRWas","executionInfo":{"status":"ok","timestamp":1648913825865,"user_tz":-120,"elapsed":465,"user":{"displayName":"Alberto Vargas","userId":"10932058389883875017"}},"outputId":"567a866b-99eb-4b9d-b4ca-e9a82bee1700"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["81\n"]}]},{"cell_type":"code","source":["!python3 run_low_shot.py --dataset=\"/content/drive/My Drive/2-Estudios/viu-master_ai/tfm-deep_vision/input/common_misclassifications/Bathroom/\" --resolution=64"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KN1HFJ_DLznH","executionInfo":{"status":"ok","timestamp":1648913966456,"user_tz":-120,"elapsed":137923,"user":{"displayName":"Alberto Vargas","userId":"10932058389883875017"}},"outputId":"f46f6c1c-0f32-4035-a284-39869a90a609"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["Loading images from \"/content/drive/My Drive/2-Estudios/viu-master_ai/tfm-deep_vision/input/common_misclassifications/Bathroom/\"\n","Creating dataset \"/content/drive/My Drive/2-Estudios/viu-master_ai/tfm-deep_vision/input/common_misclassifications/Bathroom/\"\n","Added 81 images.\n","Local submit - run_dir: results/00000-DiffAugment-stylegan2--64-batch16-1gpu-color-translation-cutout\n","dnnlib: Running training.training_loop.training_loop() on localhost...\n","Streaming data using training.dataset.TFRecordDataset...\n","Dataset shape = [3, 64, 64]\n","Dynamic range = [0, 255]\n","Label size    = 0\n","Constructing networks...\n","Setting up TensorFlow plugin \"fused_bias_act.cu\": Preprocessing... Compiling... Loading... Done.\n","Setting up TensorFlow plugin \"upfirdn_2d.cu\": Preprocessing... Compiling... Loading... Done.\n","\n","G                           Params    OutputShape       WeightShape     \n","---                         ---       ---               ---             \n","latents_in                  -         (?, 512)          -               \n","labels_in                   -         (?,)              -               \n","lod                         -         ()                -               \n","dlatent_avg                 -         (512,)            -               \n","G_mapping/latents_in        -         (?, 512)          -               \n","G_mapping/labels_in         -         (?,)              -               \n","G_mapping/Normalize         -         (?, 512)          -               \n","G_mapping/Dense0            262656    (?, 512)          (512, 512)      \n","G_mapping/Dense1            262656    (?, 512)          (512, 512)      \n","G_mapping/Dense2            262656    (?, 512)          (512, 512)      \n","G_mapping/Dense3            262656    (?, 512)          (512, 512)      \n","G_mapping/Dense4            262656    (?, 512)          (512, 512)      \n","G_mapping/Dense5            262656    (?, 512)          (512, 512)      \n","G_mapping/Dense6            262656    (?, 512)          (512, 512)      \n","G_mapping/Dense7            262656    (?, 512)          (512, 512)      \n","G_mapping/Broadcast         -         (?, 10, 512)      -               \n","G_mapping/dlatents_out      -         (?, 10, 512)      -               \n","G_synthesis/dlatents_in     -         (?, 10, 512)      -               \n","G_synthesis/4x4/Const       8192      (?, 512, 4, 4)    (1, 512, 4, 4)  \n","G_synthesis/4x4/Conv        2622465   (?, 512, 4, 4)    (3, 3, 512, 512)\n","G_synthesis/4x4/ToRGB       264195    (?, 3, 4, 4)      (1, 1, 512, 3)  \n","G_synthesis/8x8/Conv0_up    2622465   (?, 512, 8, 8)    (3, 3, 512, 512)\n","G_synthesis/8x8/Conv1       2622465   (?, 512, 8, 8)    (3, 3, 512, 512)\n","G_synthesis/8x8/Upsample    -         (?, 3, 8, 8)      -               \n","G_synthesis/8x8/ToRGB       264195    (?, 3, 8, 8)      (1, 1, 512, 3)  \n","G_synthesis/16x16/Conv0_up  2622465   (?, 512, 16, 16)  (3, 3, 512, 512)\n","G_synthesis/16x16/Conv1     2622465   (?, 512, 16, 16)  (3, 3, 512, 512)\n","G_synthesis/16x16/Upsample  -         (?, 3, 16, 16)    -               \n","G_synthesis/16x16/ToRGB     264195    (?, 3, 16, 16)    (1, 1, 512, 3)  \n","G_synthesis/32x32/Conv0_up  2622465   (?, 512, 32, 32)  (3, 3, 512, 512)\n","G_synthesis/32x32/Conv1     2622465   (?, 512, 32, 32)  (3, 3, 512, 512)\n","G_synthesis/32x32/Upsample  -         (?, 3, 32, 32)    -               \n","G_synthesis/32x32/ToRGB     264195    (?, 3, 32, 32)    (1, 1, 512, 3)  \n","G_synthesis/64x64/Conv0_up  2622465   (?, 512, 64, 64)  (3, 3, 512, 512)\n","G_synthesis/64x64/Conv1     2622465   (?, 512, 64, 64)  (3, 3, 512, 512)\n","G_synthesis/64x64/Upsample  -         (?, 3, 64, 64)    -               \n","G_synthesis/64x64/ToRGB     264195    (?, 3, 64, 64)    (1, 1, 512, 3)  \n","G_synthesis/images_out      -         (?, 3, 64, 64)    -               \n","G_synthesis/noise0          -         (1, 1, 4, 4)      -               \n","G_synthesis/noise1          -         (1, 1, 8, 8)      -               \n","G_synthesis/noise2          -         (1, 1, 8, 8)      -               \n","G_synthesis/noise3          -         (1, 1, 16, 16)    -               \n","G_synthesis/noise4          -         (1, 1, 16, 16)    -               \n","G_synthesis/noise5          -         (1, 1, 32, 32)    -               \n","G_synthesis/noise6          -         (1, 1, 32, 32)    -               \n","G_synthesis/noise7          -         (1, 1, 64, 64)    -               \n","G_synthesis/noise8          -         (1, 1, 64, 64)    -               \n","images_out                  -         (?, 3, 64, 64)    -               \n","---                         ---       ---               ---             \n","Total                       27032600                                    \n","\n","\n","D                    Params    OutputShape       WeightShape     \n","---                  ---       ---               ---             \n","images_in            -         (?, 3, 64, 64)    -               \n","Pad                  -         (?, 3, 64, 64)    -               \n","64x64/FromRGB        2048      (?, 512, 64, 64)  (1, 1, 3, 512)  \n","64x64/Conv0          2359808   (?, 512, 64, 64)  (3, 3, 512, 512)\n","64x64/Conv1_down     2359808   (?, 512, 32, 32)  (3, 3, 512, 512)\n","64x64/Skip           262144    (?, 512, 32, 32)  (1, 1, 512, 512)\n","32x32/Conv0          2359808   (?, 512, 32, 32)  (3, 3, 512, 512)\n","32x32/Conv1_down     2359808   (?, 512, 16, 16)  (3, 3, 512, 512)\n","32x32/Skip           262144    (?, 512, 16, 16)  (1, 1, 512, 512)\n","16x16/Conv0          2359808   (?, 512, 16, 16)  (3, 3, 512, 512)\n","16x16/Conv1_down     2359808   (?, 512, 8, 8)    (3, 3, 512, 512)\n","16x16/Skip           262144    (?, 512, 8, 8)    (1, 1, 512, 512)\n","8x8/Conv0            2359808   (?, 512, 8, 8)    (3, 3, 512, 512)\n","8x8/Conv1_down       2359808   (?, 512, 4, 4)    (3, 3, 512, 512)\n","8x8/Skip             262144    (?, 512, 4, 4)    (1, 1, 512, 512)\n","4x4/MinibatchStddev  -         (?, 513, 4, 4)    -               \n","4x4/Conv             2364416   (?, 512, 4, 4)    (3, 3, 513, 512)\n","4x4/Dense0           4194816   (?, 512)          (8192, 512)     \n","Output               513       (?,)              (512, 1)        \n","scores_out           -         (?,)              -               \n","---                  ---       ---               ---             \n","Total                26488833                                    \n","\n","Building TensorFlow graph...\n","Traceback (most recent call last):\n","  File \"run_low_shot.py\", line 171, in <module>\n","    main()\n","  File \"run_low_shot.py\", line 165, in main\n","    run(**vars(args))\n","  File \"run_low_shot.py\", line 94, in run\n","    dnnlib.submit_run(**kwargs)\n","  File \"/content/drive/My Drive/2-Estudios/viu-master_ai/data-efficient-gans/DiffAugment-stylegan2/dnnlib/submission/submit.py\", line 343, in submit_run\n","    return farm.submit(submit_config, host_run_dir)\n","  File \"/content/drive/My Drive/2-Estudios/viu-master_ai/data-efficient-gans/DiffAugment-stylegan2/dnnlib/submission/internal/local.py\", line 22, in submit\n","    return run_wrapper(submit_config)\n","  File \"/content/drive/My Drive/2-Estudios/viu-master_ai/data-efficient-gans/DiffAugment-stylegan2/dnnlib/submission/submit.py\", line 280, in run_wrapper\n","    run_func_obj(**submit_config.run_func_kwargs)\n","  File \"/content/drive/My Drive/2-Estudios/viu-master_ai/data-efficient-gans/DiffAugment-stylegan2/training/training_loop.py\", line 217, in training_loop\n","    G_loss, D_loss, D_reg = dnnlib.util.call_func_by_name(G=G_gpu, D=D_gpu, training_set=training_set, minibatch_size=minibatch_gpu_in, reals=reals_read, real_labels=labels_read, **loss_args)\n","  File \"/content/drive/My Drive/2-Estudios/viu-master_ai/data-efficient-gans/DiffAugment-stylegan2/dnnlib/util.py\", line 256, in call_func_by_name\n","    return func_obj(*args, **kwargs)\n","  File \"/content/drive/My Drive/2-Estudios/viu-master_ai/data-efficient-gans/DiffAugment-stylegan2/training/loss.py\", line 16, in ns_DiffAugment_r1\n","    labels = training_set.get_random_labels_tf(minibatch_size)\n","  File \"/content/drive/My Drive/2-Estudios/viu-master_ai/data-efficient-gans/DiffAugment-stylegan2/training/dataset.py\", line 193, in get_random_labels_tf\n","    return tf.zeros([minibatch_size], dtype=tf.int32)\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/array_ops.py\", line 2338, in zeros\n","    output = _constant_if_small(zero, shape, dtype, name)\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/array_ops.py\", line 2295, in _constant_if_small\n","    if np.prod(shape) < 1000:\n","  File \"<__array_function__ internals>\", line 6, in prod\n","  File \"/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py\", line 3052, in prod\n","    keepdims=keepdims, initial=initial, where=where)\n","  File \"/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py\", line 86, in _wrapreduction\n","    return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/framework/ops.py\", line 736, in __array__\n","    \" array.\".format(self.name))\n","NotImplementedError: Cannot convert a symbolic Tensor (Inputs/minibatch_gpu_in:0) to a numpy array.\n"]}]},{"cell_type":"code","source":["%ls \"/content/drive/My Drive/2-Estudios/viu-master_ai/tfm-deep_vision/input/common_misclassifications/Bathroom/\" | wc -l"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eZnBPyMZ7Chi","executionInfo":{"status":"ok","timestamp":1648913966459,"user_tz":-120,"elapsed":46,"user":{"displayName":"Alberto Vargas","userId":"10932058389883875017"}},"outputId":"08aa9fc1-e482-45ff-dcf9-ea4c3e780607"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["82\n"]}]},{"cell_type":"code","source":["asdfasdfasdfsa"],"metadata":{"id":"rdu8eNFr7DCt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# https://github.com/mit-han-lab/data-efficient-gans/tree/master/DiffAugment-stylegan2\n","!python run_low_shot.py --dataset=\"/content/drive/My Drive/2-Estudios/viu-master_ai/tfm-deep_vision/input/common_misclassifications/Bathroom/\" --DiffAugment=color,translation,cutout"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EgDAx_ocpfBc","executionInfo":{"status":"ok","timestamp":1648913658657,"user_tz":-120,"elapsed":2790,"user":{"displayName":"Alberto Vargas","userId":"10932058389883875017"}},"outputId":"c2dd5492-7635-4e8e-910e-516388332b47"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Traceback (most recent call last):\n","  File \"run_low_shot.py\", line 16, in <module>\n","    from metrics import metric_base\n","  File \"/content/drive/My Drive/2-Estudios/viu-master_ai/data-efficient-gans/DiffAugment-stylegan2/metrics/metric_base.py\", line 18, in <module>\n","    from training import dataset\n","  File \"/content/drive/My Drive/2-Estudios/viu-master_ai/data-efficient-gans/DiffAugment-stylegan2/training/dataset.py\", line 14, in <module>\n","    import tensorflow_datasets as tfds\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_datasets/__init__.py\", line 51, in <module>\n","    from tensorflow_datasets import __init__py3 as api\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_datasets/__init__py3.py\", line 43, in <module>\n","    from tensorflow_datasets.core import tf_compat\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_datasets/core/__init__.py\", line 21, in <module>\n","    tf_compat.ensure_tf_install()\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_datasets/core/tf_compat.py\", line 59, in ensure_tf_install\n","    \"This version of TensorFlow Datasets requires TensorFlow \"\n","ImportError: This version of TensorFlow Datasets requires TensorFlow version >= 2.1.0; Detected an installation of version 1.15.2. Please upgrade TensorFlow to proceed.\n"]}]},{"cell_type":"code","source":["asdfasdfasdfas"],"metadata":{"id":"j2QvJoNP68Rp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!ls \"/content/drive/My Drive/2-Estudios/viu-master_ai/tfm-deep_vision/input/common_misclassifications/Bathroom/\" | wc -l"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oTC-VdVRHkOD","executionInfo":{"status":"ok","timestamp":1648913661694,"user_tz":-120,"elapsed":485,"user":{"displayName":"Alberto Vargas","userId":"10932058389883875017"}},"outputId":"c40e20af-c0de-44b7-a6b7-78bb1cd19782"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["81\n"]}]},{"cell_type":"code","source":["import numpy\n","numpy.__version__"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"q-cpucBQ0625","executionInfo":{"status":"ok","timestamp":1648913661696,"user_tz":-120,"elapsed":12,"user":{"displayName":"Alberto Vargas","userId":"10932058389883875017"}},"outputId":"65c9aaa6-da39-4970-d861-d069dbca5d86"},"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'1.21.5'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":20}]},{"cell_type":"code","source":["asdfasdfasdfasdfasdfasd"],"metadata":{"id":"zeVkmuzUexa3","colab":{"base_uri":"https://localhost:8080/","height":167},"executionInfo":{"status":"error","timestamp":1648913663711,"user_tz":-120,"elapsed":2024,"user":{"displayName":"Alberto Vargas","userId":"10932058389883875017"}},"outputId":"7fb59465-fa62-4c99-c4f9-8cf7d629d8d9"},"execution_count":21,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-21-dbf9d50a4201>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0masdfasdfasdfasdfasdfasd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'asdfasdfasdfasdfasdfasd' is not defined"]}]},{"cell_type":"code","source":["!python3 run_low_shot.py --dataset=\"/content/drive/My Drive/2-Estudios/viu-master_ai/tfm-deep_vision/input/common_misclassifications/Bathroom/\"  --num-gpus=4"],"metadata":{"id":"DWHe1ATrVyfa","executionInfo":{"status":"aborted","timestamp":1648913663709,"user_tz":-120,"elapsed":13,"user":{"displayName":"Alberto Vargas","userId":"10932058389883875017"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!python3 run_low_shot.py --dataset=\"/content/drive/My Drive/2-Estudios/viu-master_ai/tfm-deep_vision/input/common_misclassifications/Bathroom/\""],"metadata":{"id":"whV_b0_DesOB","executionInfo":{"status":"aborted","timestamp":1648913663710,"user_tz":-120,"elapsed":14,"user":{"displayName":"Alberto Vargas","userId":"10932058389883875017"}}},"execution_count":null,"outputs":[]}]}