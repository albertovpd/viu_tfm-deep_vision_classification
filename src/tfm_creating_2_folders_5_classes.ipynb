{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k7KEbs7yDlLi"
   },
   "source": [
    "# Working with *image_dataset_from_directory()*.\n",
    "\n",
    "The first approach in this TFM was to serialize the data in a pickle and load the whole in memory => https://github.com/albertovpd/viu_tfm-deep_vision_classification/blob/main/src/TFM-serializing_data.ipynb . This is not optimal, and causes running out of RAM.\n",
    "\n",
    "Then I started using tensorflow and its *image_from_dataset* method. It allows you to batch processing and also, use data augmentation for the batches, wich needs way less memory, but is quite tricky:\n",
    "- by default, shuffle = True is set in *image_from_dataset*. That means that when using a classification report, labels in validaton dataset won't be associated with their right arrays, because it's shuffled. \n",
    "- Shuffle = False means that data is not shuffled at all, so while splitting, train_ds will have some of the classes, and val_ds will have other classes, it's like taking folders in order, without creating an heterogeneous sample for each one.\n",
    "\n",
    "So, I'll create with this notebook the  *train, test and validation folder*.\n",
    "- By the way, *image_dataset_from_director* doesn't allow you to create 3 subpartitions, just 2 (train and val).\n",
    "- The created subfolders has the same proportion than the real ones.\n",
    "\n",
    "### Final note\n",
    "You can use this notebook in your PC or Google Cloud, but I warn you that for me, Google Drive was behaving oddly, not copying all the images to the right folder (not none at all, neither all of them... Just forgetting some of them... odd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P9QvcGu9Dgky",
    "outputId": "a57396b5-0356-4393-bcb8-c71d9babd58a"
   },
   "outputs": [],
   "source": [
    "# Google Drive stuff\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive/', force_remount=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zaGu4X1PjIcW"
   },
   "source": [
    "- libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "J4MavW5KGvgS"
   },
   "outputs": [],
   "source": [
    "# local path\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import numpy as np\n",
    "import shutil\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s1a-LWavG41f"
   },
   "source": [
    "- paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "s_b-tNYrG4ky"
   },
   "outputs": [],
   "source": [
    "# for google drive\n",
    "# base_folder = \"/content/drive/My Drive/2-Estudios/viu-master_ai/tfm-deep_vision/\"\n",
    "\n",
    "# local\n",
    "load_dotenv()\n",
    "base_folder = os.environ.get(\"INPUT_PATH\")\n",
    "\n",
    "# pics located in\n",
    "root_dir  = base_folder+\"House_Room_Dataset-5_rooms/\"\n",
    "# my train/test/val folders will be created in\n",
    "input_destination = base_folder+\"dataset_2_folders/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z-IzpuPPHcuz"
   },
   "source": [
    "# splitting my data into just 2 folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iZ6Bn_O5F_o3",
    "outputId": "beb5fd86-53ee-471c-ce5a-31b05c9da6b1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Dinning', 'Bedroom', 'Livingroom', 'Kitchen', 'Bathroom']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes_dir = os.listdir(root_dir)\n",
    "classes_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aTRb-Ammbcwh",
    "outputId": "8671e612-b76f-419d-9391-0e3b2b6c82bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ***************************** \n",
      " Total images:  Dinning 1158 \n",
      " Training:  694 \n",
      " Testing:  348 \n",
      " Validation:  116 \n",
      " *****************************\n",
      "\n",
      " ***************************** \n",
      " Total images:  Bedroom 1248 \n",
      " Training:  748 \n",
      " Testing:  375 \n",
      " Validation:  125 \n",
      " *****************************\n",
      "\n",
      " ***************************** \n",
      " Total images:  Livingroom 1273 \n",
      " Training:  763 \n",
      " Testing:  382 \n",
      " Validation:  128 \n",
      " *****************************\n",
      "\n",
      " ***************************** \n",
      " Total images:  Kitchen 965 \n",
      " Training:  579 \n",
      " Testing:  289 \n",
      " Validation:  97 \n",
      " *****************************\n",
      "\n",
      " ***************************** \n",
      " Total images:  Bathroom 606 \n",
      " Training:  363 \n",
      " Testing:  182 \n",
      " Validation:  61 \n",
      " *****************************\n"
     ]
    }
   ],
   "source": [
    "train_ratio = 0.6\n",
    "val_ratio  = 0.1\n",
    "\n",
    "for cls in classes_dir:\n",
    "    os.makedirs(input_destination +'train_ds/' + cls, exist_ok=True)\n",
    "    os.makedirs(input_destination +'test_ds/' + cls, exist_ok=True)\n",
    "    os.makedirs(input_destination +'val_ds/' + cls, exist_ok=True)\n",
    "    \n",
    "    # for each class, let's counts its elements\n",
    "    src = root_dir + cls\n",
    "    allFileNames = os.listdir(src)\n",
    "\n",
    "    # shuffle it and split into train/test/va\n",
    "    np.random.shuffle(allFileNames)\n",
    "    train_FileNames, test_FileNames, val_FileNames = np.split(np.array(allFileNames),[int(train_ratio * len(allFileNames)), int((1-val_ratio) * len(allFileNames))])\n",
    "    \n",
    "    # save their initial path\n",
    "    train_FileNames = [src+'/'+ name  for name in train_FileNames.tolist()]\n",
    "    test_FileNames  = [src+'/' + name for name in test_FileNames.tolist()]\n",
    "    val_FileNames   = [src+'/' + name for name in val_FileNames.tolist()]\n",
    "    print(\"\\n *****************************\",\n",
    "          \"\\n Total images: \",cls, len(allFileNames),\n",
    "          '\\n Training: ', len(train_FileNames),\n",
    "          '\\n Testing: ', len(test_FileNames),\n",
    "          '\\n Validation: ', len(val_FileNames),\n",
    "          '\\n *****************************')\n",
    "    \n",
    "    # copy files from the initial path to the final folders\n",
    "    for name in train_FileNames:\n",
    "      shutil.copy(name, input_destination +'train_ds/' + cls)\n",
    "    for name in test_FileNames:\n",
    "      shutil.copy(name, input_destination +'test_ds/' + cls)\n",
    "    for name in val_FileNames:\n",
    "      shutil.copy(name, input_destination +'val_ds/' + cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jbTXk039vjW3",
    "outputId": "2d89d970-0946-40a9-acce-031ed2abd2b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/vargas/Documents/data/viu_tfm-deep_vision_classification/input/dataset_2_folders/train_ds/   train_ds/ 0\n",
      "/home/vargas/Documents/data/viu_tfm-deep_vision_classification/input/dataset_2_folders/train_ds/Dinning   train_ds/ 694\n",
      "/home/vargas/Documents/data/viu_tfm-deep_vision_classification/input/dataset_2_folders/train_ds/Bedroom   train_ds/ 748\n",
      "/home/vargas/Documents/data/viu_tfm-deep_vision_classification/input/dataset_2_folders/train_ds/Livingroom   train_ds/ 763\n",
      "/home/vargas/Documents/data/viu_tfm-deep_vision_classification/input/dataset_2_folders/train_ds/Kitchen   train_ds/ 579\n",
      "/home/vargas/Documents/data/viu_tfm-deep_vision_classification/input/dataset_2_folders/train_ds/Bathroom   train_ds/ 363\n",
      "/home/vargas/Documents/data/viu_tfm-deep_vision_classification/input/dataset_2_folders/test_ds/   test_ds/ 0\n",
      "/home/vargas/Documents/data/viu_tfm-deep_vision_classification/input/dataset_2_folders/test_ds/Dinning   test_ds/ 348\n",
      "/home/vargas/Documents/data/viu_tfm-deep_vision_classification/input/dataset_2_folders/test_ds/Bedroom   test_ds/ 375\n",
      "/home/vargas/Documents/data/viu_tfm-deep_vision_classification/input/dataset_2_folders/test_ds/Livingroom   test_ds/ 382\n",
      "/home/vargas/Documents/data/viu_tfm-deep_vision_classification/input/dataset_2_folders/test_ds/Kitchen   test_ds/ 289\n",
      "/home/vargas/Documents/data/viu_tfm-deep_vision_classification/input/dataset_2_folders/test_ds/Bathroom   test_ds/ 182\n",
      "/home/vargas/Documents/data/viu_tfm-deep_vision_classification/input/dataset_2_folders/val_ds/   val_ds/ 0\n",
      "/home/vargas/Documents/data/viu_tfm-deep_vision_classification/input/dataset_2_folders/val_ds/Dinning   val_ds/ 116\n",
      "/home/vargas/Documents/data/viu_tfm-deep_vision_classification/input/dataset_2_folders/val_ds/Bedroom   val_ds/ 125\n",
      "/home/vargas/Documents/data/viu_tfm-deep_vision_classification/input/dataset_2_folders/val_ds/Livingroom   val_ds/ 128\n",
      "/home/vargas/Documents/data/viu_tfm-deep_vision_classification/input/dataset_2_folders/val_ds/Kitchen   val_ds/ 97\n",
      "/home/vargas/Documents/data/viu_tfm-deep_vision_classification/input/dataset_2_folders/val_ds/Bathroom   val_ds/ 61\n"
     ]
    }
   ],
   "source": [
    "# checking everything was fine\n",
    "paths = ['train_ds/', 'test_ds/','val_ds/']\n",
    "for p in paths:\n",
    "  for dir,subdir,files in os.walk(input_destination + p):\n",
    "    print(dir,' ', p, str(len(files)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_i67exvFiov6"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "tfm-creating_2_folders_5_classes.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
