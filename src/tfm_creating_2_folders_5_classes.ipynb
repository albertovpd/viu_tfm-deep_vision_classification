{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tfm-creating_2_folders_5_classes.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Working with *image_dataset_from_directory()*.\n",
        "\n",
        "The first approach in this TFM was to serialize the data in a pickle and load the whole in memory => https://github.com/albertovpd/viu_tfm-deep_vision_classification/blob/main/src/TFM-serializing_data.ipynb . This is not optimal, and causes running out of RAM.\n",
        "\n",
        "Then I started using tensorflow and its *image_from_dataset* method. It allows you to batch processing and also, use data augmentation for the batches, wich needs way less memory, but is quite tricky:\n",
        "- by default, shuffle = True is set in *image_from_dataset*. That means that when using a classification report, labels in validaton dataset won't be associated with their right arrays, because it's shuffled. \n",
        "- Shuffle = False means that data is not shuffled at all, so while splitting, train_ds will have some of the classes, and val_ds will have other classes, it's like taking folders in order, without creating an heterogeneous sample for each one.\n",
        "\n",
        "So, let's use some sklearn to create 2 heterogeneous folders: *train_folder* and *val_folder*.\n",
        "- I create 2 folders because at first, the *image_from_dataset* method works just with 2 sets (not the typical train-test-validation). Than by the way can be modified later.\n",
        "- They'll contain the same proportion than our dataset. For that purpose, we have to use **stratify** in sklarn.train_test_split."
      ],
      "metadata": {
        "id": "k7KEbs7yDlLi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P9QvcGu9Dgky",
        "outputId": "a57396b5-0356-4393-bcb8-c71d9babd58a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "# Google Drive stuff\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/', force_remount=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- libraries"
      ],
      "metadata": {
        "id": "zaGu4X1PjIcW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import shutil\n",
        "import random"
      ],
      "metadata": {
        "id": "J4MavW5KGvgS"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- paths"
      ],
      "metadata": {
        "id": "s1a-LWavG41f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_folder = \"/content/drive/My Drive/2-Estudios/viu-master_ai/tfm-deep_vision/\"\n",
        "input = base_folder+\"input/House_Room_Dataset-5_rooms/\" # for requesting directly pics\n",
        "input_destination = base_folder+\"input/dataset_2_folders/\""
      ],
      "metadata": {
        "id": "s_b-tNYrG4ky"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# splitting my data into just 2 folders"
      ],
      "metadata": {
        "id": "Z-IzpuPPHcuz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir(input)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iZ6Bn_O5F_o3",
        "outputId": "beb5fd86-53ee-471c-ce5a-31b05c9da6b1"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Kitchen', 'Livingroom', 'Bathroom', 'Bedroom', 'Dinning']"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import shutil\n",
        "import random\n",
        "root_dir = base_folder+\"input/House_Room_Dataset-5_rooms/\" # for requesting directly pics\n",
        "classes_dir = os.listdir(root_dir)\n",
        "\n",
        "train_ratio = 0.6\n",
        "val_ratio  = 0.1\n",
        "\n",
        "for cls in classes_dir:\n",
        "    os.makedirs(input_destination +'train_ds/' + cls, exist_ok=True)\n",
        "    os.makedirs(input_destination +'test_ds/' + cls, exist_ok=True)\n",
        "    os.makedirs(input_destination +'val_ds/' + cls, exist_ok=True)\n",
        "    \n",
        "    # for each class, let's counts its elements\n",
        "    src = root_dir + cls\n",
        "    allFileNames = os.listdir(src)\n",
        "\n",
        "    # shuffle it and split into train/test/va\n",
        "    np.random.shuffle(allFileNames)\n",
        "    train_FileNames, test_FileNames, val_FileNames = np.split(np.array(allFileNames),[int(train_ratio * len(allFileNames)), int((1-val_ratio) * len(allFileNames))])\n",
        "    \n",
        "    # save their initial path\n",
        "    train_FileNames = [src+'/'+ name  for name in train_FileNames.tolist()]\n",
        "    test_FileNames  = [src+'/' + name for name in test_FileNames.tolist()]\n",
        "    val_FileNames   = [src+'/' + name for name in val_FileNames.tolist()]\n",
        "    print(\"\\n *****************************\",\n",
        "          \"\\n Total images: \",cls, len(allFileNames),\n",
        "          '\\n Training: ', len(train_FileNames),\n",
        "          '\\n Testing: ', len(test_FileNames),\n",
        "          '\\n Validation: ', len(val_FileNames),\n",
        "          '\\n *****************************')\n",
        "    \n",
        "    # copy files from the initial path to the final folders\n",
        "    for name in train_FileNames:\n",
        "      shutil.copy(name, input_destination +'train_ds/' + cls)\n",
        "    for name in test_FileNames:\n",
        "      shutil.copy(name, input_destination +'test_ds/' + cls)\n",
        "    for name in val_FileNames:\n",
        "      shutil.copy(name, input_destination +'val_ds/' + cls)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aTRb-Ammbcwh",
        "outputId": "8671e612-b76f-419d-9391-0e3b2b6c82bf"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " ***************************** \n",
            " Total images:  Kitchen 965 \n",
            " Training:  579 \n",
            " Testing:  289 \n",
            " Validation:  97 \n",
            " *****************************\n",
            "\n",
            " ***************************** \n",
            " Total images:  Livingroom 1273 \n",
            " Training:  763 \n",
            " Testing:  382 \n",
            " Validation:  128 \n",
            " *****************************\n",
            "\n",
            " ***************************** \n",
            " Total images:  Bathroom 606 \n",
            " Training:  363 \n",
            " Testing:  182 \n",
            " Validation:  61 \n",
            " *****************************\n",
            "\n",
            " ***************************** \n",
            " Total images:  Bedroom 1248 \n",
            " Training:  748 \n",
            " Testing:  375 \n",
            " Validation:  125 \n",
            " *****************************\n",
            "\n",
            " ***************************** \n",
            " Total images:  Dinning 1158 \n",
            " Training:  694 \n",
            " Testing:  348 \n",
            " Validation:  116 \n",
            " *****************************\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# checking everything was fine\n",
        "paths = ['train_ds/', 'test_ds/','val_ds/']\n",
        "for p in paths:\n",
        "  for dir,subdir,files in os.walk(input_destination + p):\n",
        "    print(dir,' ', p, str(len(files)))"
      ],
      "metadata": {
        "id": "jbTXk039vjW3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d89d970-0946-40a9-acce-031ed2abd2b2"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/2-Estudios/viu-master_ai/tfm-deep_vision/input/dataset_2_folders/train_ds/   train_ds/ 0\n",
            "/content/drive/My Drive/2-Estudios/viu-master_ai/tfm-deep_vision/input/dataset_2_folders/train_ds/Kitchen   train_ds/ 579\n",
            "/content/drive/My Drive/2-Estudios/viu-master_ai/tfm-deep_vision/input/dataset_2_folders/train_ds/Livingroom   train_ds/ 763\n",
            "/content/drive/My Drive/2-Estudios/viu-master_ai/tfm-deep_vision/input/dataset_2_folders/train_ds/Bathroom   train_ds/ 363\n",
            "/content/drive/My Drive/2-Estudios/viu-master_ai/tfm-deep_vision/input/dataset_2_folders/train_ds/Bedroom   train_ds/ 748\n",
            "/content/drive/My Drive/2-Estudios/viu-master_ai/tfm-deep_vision/input/dataset_2_folders/train_ds/Dinning   train_ds/ 694\n",
            "/content/drive/My Drive/2-Estudios/viu-master_ai/tfm-deep_vision/input/dataset_2_folders/test_ds/   test_ds/ 0\n",
            "/content/drive/My Drive/2-Estudios/viu-master_ai/tfm-deep_vision/input/dataset_2_folders/test_ds/Kitchen   test_ds/ 289\n",
            "/content/drive/My Drive/2-Estudios/viu-master_ai/tfm-deep_vision/input/dataset_2_folders/test_ds/Livingroom   test_ds/ 382\n",
            "/content/drive/My Drive/2-Estudios/viu-master_ai/tfm-deep_vision/input/dataset_2_folders/test_ds/Bathroom   test_ds/ 182\n",
            "/content/drive/My Drive/2-Estudios/viu-master_ai/tfm-deep_vision/input/dataset_2_folders/test_ds/Bedroom   test_ds/ 375\n",
            "/content/drive/My Drive/2-Estudios/viu-master_ai/tfm-deep_vision/input/dataset_2_folders/test_ds/Dinning   test_ds/ 348\n",
            "/content/drive/My Drive/2-Estudios/viu-master_ai/tfm-deep_vision/input/dataset_2_folders/val_ds/   val_ds/ 0\n",
            "/content/drive/My Drive/2-Estudios/viu-master_ai/tfm-deep_vision/input/dataset_2_folders/val_ds/Kitchen   val_ds/ 97\n",
            "/content/drive/My Drive/2-Estudios/viu-master_ai/tfm-deep_vision/input/dataset_2_folders/val_ds/Livingroom   val_ds/ 128\n",
            "/content/drive/My Drive/2-Estudios/viu-master_ai/tfm-deep_vision/input/dataset_2_folders/val_ds/Bathroom   val_ds/ 61\n",
            "/content/drive/My Drive/2-Estudios/viu-master_ai/tfm-deep_vision/input/dataset_2_folders/val_ds/Bedroom   val_ds/ 125\n",
            "/content/drive/My Drive/2-Estudios/viu-master_ai/tfm-deep_vision/input/dataset_2_folders/val_ds/Dinning   val_ds/ 116\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "_i67exvFiov6"
      },
      "execution_count": 40,
      "outputs": []
    }
  ]
}