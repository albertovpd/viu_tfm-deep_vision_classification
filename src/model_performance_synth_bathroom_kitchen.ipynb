{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EPEYaS0dA_Pd"
      },
      "source": [
        "# Studying a model performance with synthetic data\n",
        "\n",
        "Synthetic data have been created for each class, using as input the pictures that all models misclassify. The idea is the following: Maybe having more pics similar to the misclassified ones we can improve the performance of the model in that areas.\n",
        "\n",
        "In this notebook the train set of kitchen and bathroom classes have been populated with synthetic data (480 for bathroom, 250 for kitchen), then all classes have approx the same volume.\n",
        "\n",
        "- The study of what pics were generated synthetically can be found here => https://github.com/albertovpd/viu_tfm-deep_vision_classification/tree/synthetic_data_study\n",
        "\n",
        "- They were created using the pytorch implementation of this repo => https://github.com/mit-han-lab/data-efficient-gans\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UnrItHohA1UI",
        "outputId": "36d5a27b-7323-48a7-b47c-b7b2bea02cef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "# Google Drive stuff\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QXg1WfU_B6SI",
        "outputId": "7688af50-fe59-4ca0-eb04-b8baaf461575"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun May 22 17:08:43 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P0    23W / 300W |      0MiB / 16160MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-I_tE0o9CCGh",
        "outputId": "c9e7e43c-ecbc-4bca-be64-026e9d190854"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ],
      "source": [
        "# tf\n",
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQ-gURRuCOla"
      },
      "source": [
        "- libs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "dpShKkBeCL48"
      },
      "outputs": [],
      "source": [
        "%tensorflow_version 2.x\n",
        "# batch ingestion of pics without pickle\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
        "\n",
        "# nns\n",
        "from tensorflow.keras.applications import ResNet50 \n",
        "\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.models import load_model # Sequential\n",
        "from tensorflow.keras import layers \n",
        "\n",
        "# optimization\n",
        "from tensorflow.keras.optimizers import SGD #Adam\n",
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy, categorical_crossentropy\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# nn architectures, metrics, viz & reports => written in my_functions202202 file\n",
        "import sys\n",
        "sys.path.append(\"/content/drive/My Drive/2-Estudios/viu-master_ai/tfm-deep_vision/src\")\n",
        "from my_functions202202 import generic_last_2layers, plotting_model, model_evaluation, classification_report_pic, confusion_matrix_report\n",
        "\n",
        "import numpy as np\n",
        "%matplotlib inline\n",
        "\n",
        "# navigating through folder\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z9du-AOzCVQ5"
      },
      "source": [
        "- paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "cU4Q7459CTE1"
      },
      "outputs": [],
      "source": [
        "base_folder = \"/content/drive/My Drive/2-Estudios/viu-master_ai/tfm-deep_vision/\"\n",
        "train_folder = base_folder + \"input/dataset_synth_data-augmented_bathroom_kitchen/train_ds/\"\n",
        "val_folder = base_folder + \"input/dataset_synth_data-augmented_bathroom_kitchen/val_ds/\"\n",
        "test_folder = base_folder+\"input/dataset_synth_data-augmented_bathroom_kitchen/test_ds/\"\n",
        "\n",
        "src_folder =  base_folder+\"src/\"\n",
        "output_folder = base_folder + \"/output/\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENhx47E8C9ul"
      },
      "source": [
        "- functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "LSaIpHb7C98L"
      },
      "outputs": [],
      "source": [
        "#my_functions202202.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RdQj8JY5DV-p"
      },
      "source": [
        "- common parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "fLqarfuvDvYi"
      },
      "outputs": [],
      "source": [
        "image_size = (128,128)\n",
        "batch_size = 128\n",
        "epochs = 250\n",
        "opt = SGD(momentum=0.9) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "mq54z9khFNLI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d81e5ee-3ed2-4f34-fa6e-87fc83671d87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94773248/94765736 [==============================] - 0s 0us/step\n",
            "94781440/94765736 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "base_model_resnet50 = ResNet50(include_top=False, weights='imagenet', input_shape=(128, 128, 3), classes = 5) \n",
        "models_dict = {\"resnet50_NOdataAug_dropoutFirst007\": \n",
        "         generic_last_2layers(data_augmentation= None, nn=base_model_resnet50, neurons_final_layer=5, dropout_layers=True,  dropout_position=\"first\",  dropout_percent = 0.07)\n",
        "         }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "id": "kXaVUUVFCQQP",
        "outputId": "82885ff6-653a-446d-c3f1-53842752080d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 0 files belonging to 5 classes.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-a1633689ecb6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m       \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m       \u001b[0mcolor_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rgb'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m       \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/preprocessing/image_dataset.py\u001b[0m in \u001b[0;36mimage_dataset_from_directory\u001b[0;34m(directory, labels, label_mode, class_names, color_mode, batch_size, image_size, shuffle, seed, validation_split, subset, interpolation, follow_links, crop_to_aspect_ratio, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m       image_paths, labels, validation_split, subset)\n\u001b[1;32m    208\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mimage_paths\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m     raise ValueError(f'No images found in directory {directory}. '\n\u001b[0m\u001b[1;32m    210\u001b[0m                      f'Allowed formats: {ALLOWLIST_FORMATS}')\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: No images found in directory /content/drive/My Drive/2-Estudios/viu-master_ai/tfm-deep_vision/input/dataset_synth_data-augmented_bathroom_kitchen/train_ds/. Allowed formats: ('.bmp', '.gif', '.jpeg', '.jpg', '.png')"
          ]
        }
      ],
      "source": [
        "train_ds = image_dataset_from_directory(\n",
        "    train_folder,\n",
        "      class_names=[\"Bedroom\",\"Bathroom\",\"Dinning\",\"Livingroom\",\"Kitchen\"],\n",
        "      seed=None,\n",
        "      validation_split=None, \n",
        "      subset=None,\n",
        "      image_size= image_size,\n",
        "      batch_size= batch_size,\n",
        "      color_mode='rgb',\n",
        "      shuffle=False \n",
        "  )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_ds = image_dataset_from_directory(\n",
        "    val_folder,\n",
        "      class_names=[\"Bedroom\",\"Bathroom\",\"Dinning\",\"Livingroom\",\"Kitchen\"],\n",
        "      seed=None,\n",
        "      validation_split=None, \n",
        "      subset=None,\n",
        "      image_size= image_size,\n",
        "      batch_size= batch_size,\n",
        "      color_mode='rgb',\n",
        "      shuffle=False \n",
        "  )"
      ],
      "metadata": {
        "id": "x-TtkePlwOvt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nrnMLMpIja6S",
        "outputId": "d32ddad6-57df-481b-f210-1da36a82617e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 249 files belonging to 5 classes.\n"
          ]
        }
      ],
      "source": [
        "test_ds = image_dataset_from_directory(\n",
        "    test_folder,\n",
        "      class_names=[\"Bedroom\",\"Bathroom\",\"Dinning\",\"Livingroom\",\"Kitchen\"],\n",
        "      seed=None,\n",
        "      validation_split=None, \n",
        "      subset=None,\n",
        "      image_size= image_size,\n",
        "      batch_size= batch_size,\n",
        "      color_mode='rgb',\n",
        "      shuffle=False \n",
        "  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ds1JAkI6Ex89"
      },
      "outputs": [],
      "source": [
        "# name for pics\n",
        "f = \"augmented_bathroom_kitchen\"\n",
        "\n",
        "class_names = train_ds.class_names\n",
        "print(class_names)\n",
        "\n",
        "# checking numbers non sense now because all have same volume\n",
        "paths = [train_folder, val_folder, test_folder]\n",
        "for p in paths:\n",
        "    for dir,subdir,files in os.walk(p):\n",
        "        print(dir,' => ', p, str(len(files)))\n",
        "\n",
        "# calling model\n",
        "model_name, nn = list(models_dict.items())[0]\n",
        "print(\"\\n\", model_name)\n",
        "nn.summary()\n",
        "\n",
        "nn.compile( optimizer = opt, #\"adam\", \n",
        "              loss=SparseCategoricalCrossentropy(from_logits=True) ,#'categorical_crossentropy', \n",
        "              metrics=['accuracy'] # \"recall\"\n",
        "              )\n",
        "\n",
        "# ====== USING VAL DATASET ======\n",
        "\n",
        "history = nn.fit(\n",
        "      train_ds,\n",
        "      validation_data=val_ds,\n",
        "      epochs=epochs,\n",
        "      #callbacks = callbacks # <=== REMOVE CALLBACK for full results\n",
        "      )\n",
        "\n",
        "number_of_epochs_it_ran = len(history.history['loss']) \n",
        "print(\"run epochs: \",number_of_epochs_it_ran)\n",
        "name = model_name+ f \n",
        "#models_dict[m].save(output_folder+name+\".h5\")\n",
        "\n",
        "# saving model accuracy/loss graph\n",
        "plotting_model(history,number_of_epochs_it_ran, name, output_folder, \"val\") \n",
        "\n",
        "# saving model metrics to json\n",
        "evaluation = nn.evaluate(test_ds, batch_size=batch_size, return_dict=True)\n",
        "model_evaluation(evaluation, output_folder, name+\"_trainVal\")\n",
        "\n",
        "# get inferences\n",
        "y_pred_val_float = nn.predict(val_ds)\n",
        "y_pred_val = np.argmax(y_pred_val_float, axis=1)\n",
        "\n",
        "# get real labels\n",
        "y_target = tf.concat([y for x, y in val_ds], axis=0) \n",
        "\n",
        "# classification and confusion matrix reports\n",
        "classification_report_pic(y_pred_val, y_target,  class_names, output_folder, name+\"_trainVal\")\n",
        "confusion_matrix_report(y_pred_val, y_target, class_names, output_folder, name+\"_trainVal\")\n",
        "\n",
        "# ====== USING TEST DATASET ======\n",
        "\n",
        "# saving model metrics to json\n",
        "evaluation_test = nn.evaluate(test_ds, batch_size=batch_size, return_dict=True)\n",
        "model_evaluation(evaluation_test, output_folder, name+\"_trainTest\")\n",
        "\n",
        "# get inferences\n",
        "y_pred_test_float = nn.predict(test_ds)\n",
        "y_pred_test = np.argmax(y_pred_test_float, axis=1)\n",
        "\n",
        "# get real labels for val_ds\n",
        "y_target_test = tf.concat([y for x, y in test_ds], axis=0) \n",
        "\n",
        "# classification and confusion matrix reports\n",
        "classification_report_pic(y_pred_test, y_target_test,  class_names, output_folder, name+\"_trainTest\")\n",
        "confusion_matrix_report(y_pred_test, y_target_test, class_names, output_folder, name+\"_trainTest\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n_wCtMxyt3Dj"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "background_execution": "on",
      "collapsed_sections": [],
      "name": "synth-augmented_bathroom_kitchen.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}